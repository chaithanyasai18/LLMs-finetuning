{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jurbKyp_LEOG"
      },
      "source": [
        "# **Dataset Preparation** \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Zephyr-7b-beta\n",
        "\n",
        "\n",
        "## Instruction Prompt Template - Dataset from meta_data folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd # type: ignore\n",
        "\n",
        "dataset_path = \"./data/meta_data/data.csv\"\n",
        "\n",
        "prompt_template = \"\"\"<|system|>\\n You are a safe, ethical, helpful, knowledgeable AI assistant and customer support expert specialising in cyber security, cloud computing and IT technical Support domains. Your primary job is to deliver detailed responses to customer questions in these domains. Drawing on your extensive expertise, adhere to the following guidelines:\\n\n",
        "\n",
        "1. Provide concise, accurate, and helpful answers to these questions, typically ranging from 450 - 500 words, depending on the complexity of the question.\\n\n",
        "\n",
        "2. Enhance readability by using appropriate formatting such as bullet points, short paragraphs, or numbered lists when applicable.\\n\n",
        "\n",
        "3. Prioritize customer satisfaction while maintaining an empathetic, human and professional tone throughout interactions.\\n\n",
        "\n",
        "4. Provide troubleshooting steps in a clear, organised and logical order when applicable.\\n\n",
        "\n",
        "5. Avoid providing information that could be harmful, biased, misused or leading to security risks or data loss.\\n \n",
        "\n",
        "</s>\\n<|user|>\\n Question: {Question}\\n\n",
        "\n",
        "Answer: </s>\\n<|assistant|>\\n\n",
        "\n",
        "\"\"\"\n",
        "output_column_name = \"Answer\"\n",
        "\n",
        "df = pd.read_csv(dataset_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## meta_data/data - 80% train and 20% Evaluation\n",
        "\n",
        "### Utility function for mapping from existing split columns (0,1,2) to new \"train\" and \"evaluation\".\n",
        "### For 0 is mapped to \"Train\"  and 1 & 2 is mapped to \"Evaluation\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd # type: ignore\n",
        "import numpy as np # type: ignore\n",
        "\n",
        "def map_split(value):\n",
        "    if value == 'train':\n",
        "        return 'train'\n",
        "    else:\n",
        "        return 'evaluation'\n",
        "\n",
        "# Read the CSV file\n",
        "#df = pd.read_csv('your_file.csv')\n",
        "\n",
        "# Check if there's an existing split column\n",
        "if 'existing_split' in df.columns:\n",
        "    # Map the existing split column to the new 'split' column\n",
        "    df['split'] = df['existing_split'].apply(map_split)\n",
        "else:\n",
        "    # Create a new 'split' column with 70-30 split\n",
        "    df['split'] = np.random.choice(['train', 'evaluation'], size=len(df), p=[0.8, 0.2])\n",
        "\n",
        "# Save the updated DataFrame back to CSV\n",
        "df.to_csv('./data/Zephyr/data.csv', index=False)\n",
        "print(\"Dataset created successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the split values in counts and percentages\n",
        "counts = df['split'].value_counts()\n",
        "percentages = df['split'].value_counts(normalize=True)\n",
        "\n",
        "# Combine counts and percentages into a single DataFrame\n",
        "result = pd.DataFrame({'Count': counts, 'Percentage': percentages})\n",
        "\n",
        "# Format the percentage as a string with two decimal places\n",
        "result['Percentage'] = result['Percentage'].apply(lambda x: f\"{x:.3%}\")\n",
        "\n",
        "# Print the result\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the style\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('./data/Zephyr/data.csv')\n",
        "\n",
        "# Create a figure with subplots\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Define a color palette\n",
        "color_palette = sns.color_palette(\"colorblind\")[:2]  # Get the first two colors from the colorblind palette\n",
        "\n",
        "# Get the split counts\n",
        "split_counts = df['split'].value_counts()\n",
        "\n",
        "# 1. Pie chart\n",
        "wedges, texts, autotexts = ax1.pie(split_counts, labels=split_counts.index, autopct='%1.1f%%', \n",
        "                                   startangle=90, colors=color_palette)\n",
        "ax1.set_title('Distribution of Train and Evaluation Sets')\n",
        "\n",
        "# Add count numbers to pie chart\n",
        "for i, autotext in enumerate(autotexts):\n",
        "    autotext.set_text(f'{split_counts[i]} ({autotext.get_text()})')\n",
        "\n",
        "# 2. Bar plot\n",
        "sns.countplot(x='split', data=df, ax=ax2, palette=dict(zip(split_counts.index, color_palette)))\n",
        "ax2.set_title('Count of Samples in Train and Evaluation Sets')\n",
        "ax2.set_ylabel('Number of Samples')\n",
        "\n",
        "# Add count numbers on top of each bar\n",
        "for i, p in enumerate(ax2.patches):\n",
        "    height = p.get_height()\n",
        "    ax2.text(p.get_x() + p.get_width()/2., height + 0.1,\n",
        "             f'{height}',\n",
        "             ha=\"center\", va=\"bottom\")\n",
        "\n",
        "# Adjust layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_df = pd.DataFrame()\n",
        "prompts = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    prompt = prompt_template.format(**row.to_dict())\n",
        "    prompts.append(prompt)\n",
        "\n",
        "new_df[\"prompt\"] = prompts\n",
        "new_df[\"completion\"] = df[output_column_name]\n",
        "\n",
        "if \"split\" in df.columns:\n",
        "    # Modify this line\n",
        "    new_df['split'] = df['split'].apply(map_split)\n",
        "\n",
        "print(new_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset saved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMIugu-DOprG"
      },
      "outputs": [],
      "source": [
        "new_df.to_csv(\"./data/Zephyr/data.csv\", index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
