# Hugging Face Authentication
# Get your token from: https://huggingface.co/settings/tokens
HUGGINGFACE_TOKEN=hf_your_token_here

# Weights & Biases Authentication
# Get your token from: https://wandb.ai/authorize
WANDB_TOKEN=your_wandb_token_here

# CUDA Configuration (Optional)
# Specify which GPUs to use (comma-separated)
CUDA_VISIBLE_DEVICES=0

# Training Configuration (Optional - can override via command line)
WANDB_PROJECT=qlora-finetuning
WANDB_ENTITY=your_wandb_username

# Hugging Face Hub Configuration
HF_HUB_CACHE=/path/to/cache
HF_HOME=/path/to/hf_home

# Model-specific settings
TORCH_DTYPE=auto
TRANSFORMERS_CACHE=/path/to/transformers_cache

# Debugging and Logging
TRANSFORMERS_VERBOSITY=error
DATASETS_VERBOSITY=error

# Optional: Distributed Training
MASTER_ADDR=localhost
MASTER_PORT=29500
WORLD_SIZE=1
RANK=0

# Optional: Memory Management
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128

# Optional: Performance Tuning
OMP_NUM_THREADS=8
MKL_NUM_THREADS=8
